{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature-engineering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/feature-engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eul3RkG3UQDU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "metadata": {
        "id": "1MGLipHpUeV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Most critical and time consuming part of model building.\n",
        "* Trial and error process.\n",
        "* The choice of features influences results. Answers questions like: \n",
        "* Have new features been identified?\n",
        "* How to incorporate them into the model?\n",
        "* Which features should be used and which are just noise? \n",
        "* Converting raw data into a higher representation of the data through Data Preparation.\n",
        "* Typically for Unsupervised Learning, defining how to measure distance between training examples and ultimately between classifiers and new instances.\n",
        "* Typically for Unsupervised Learning, decide how to weight the relative importance"
      ]
    },
    {
      "metadata": {
        "id": "kO10GaOmUqJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation Techniques\n",
        "\n",
        "* **Data Cleansing** - Identify and remove or correct any missing data, invalid data, etc.\n",
        "* **Imputation** - Process by which missing data is replaced with a calculated guess. For example, the mean or median values of the Feature.\n",
        "* **Shuffling and Binning** - Shuffle or bin the training data so the algorithm does not learn based on the order of the data.\n",
        "* **Feature Scaling** - Sometimes a needed Feature larger in range than  others. For example a personâ€™s age could be a larger range than other feature because an age can be anywhere from 0 years to over 100 years adding too much weight or distance to those points. This leads to an underfit model. In this instance we scale the feature vectors. This is where we need to convert raw data into a higher representation of the data.\n",
        "* **Z-Scaling** - This is the standard scale in statistics where each element (feature vector) is divided by the standard deviation of each value for a feature. This is the most common practice to convert certain Features (or Dimensions).\n",
        "* **Interpolation** - Take the smallest value within the Feature set and call it 0 and the largest value in the Feature set is 1.\f\n"
      ]
    },
    {
      "metadata": {
        "id": "JwNMRrvwUkpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}