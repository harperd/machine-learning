{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "univariate-linear-regression-with-gradient-descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/notebooks/univariate-linear-regression-with-gradient-descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5PT6bd4V65",
        "colab_type": "text"
      },
      "source": [
        "# Univariate Linear Regression and Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0aXI4RCl7E",
        "colab_type": "text"
      },
      "source": [
        "## Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kq34XhwCpyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NumPy adds support for large, multi-dimensional arrays and matrices, along with a large collection \n",
        "# of high-level mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib is a plotting library for the Python programming language and its numerical mathematics \n",
        "# extension NumPy. It provides an object-oriented API for embedding plots into applications using \n",
        "# general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Pandas is a software library for data manipulation and analysis. In particular, it offers data \n",
        "# structures and operations for manipulating numerical tables and time series.\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zek8oIAP5YQH",
        "colab_type": "text"
      },
      "source": [
        "# Hypothesis Function\n",
        "\n",
        "In machine learning, a *hypothesis* function is used to predict outcomes or $y$ values. Below is the univariate linear regression hypothesis function where theta ($\\theta$) can represent any two numbers and $h_\\theta(x)$ or $y$ is our *prediction*. We just have to figure out what those two numbers are that allow the function to best intersect our data or features. It's a simple linear equation but finding the best theta values is where the challenge lies.\n",
        "\n",
        "> $h_{\\theta }( x) =\\theta _{0} \\ +\\ \\theta _{1} x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFuhgcny3XzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hypothesis Function - This function will compute predictions for all features. \n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     X: A DataFrame containing the features to create predictions against.\n",
        "def hypothesis(theta, X):\n",
        "    # Here, X is a Pandas DataFrame containing all of our data.\n",
        "    # X.shape returns tuple of the shape's dimentions in rows x columns.\n",
        "    # Therefore, X.shape[0] will get us the number of rows, or features.\n",
        "    # num_features = X.shape[0]\n",
        "    num_features = len(X)\n",
        "    \n",
        "    # numpy.ones returns a new array of given shape, filled with ones.\n",
        "    # Here, we want a new array (vector) of size num_features x 1 (rows x columns).\n",
        "    h = np.ones((num_features, 1))\n",
        "    \n",
        "    # Loop through each feature (x) in our data set.\n",
        "    #\n",
        "    # TODO: Perform this in a more optimal manner using matrix multiplication\n",
        "    #       against the entire feature set, X.\n",
        "    for i in range(0, num_features):\n",
        "        # Get the next feature value.\n",
        "        feature_value = X[i]\n",
        "        \n",
        "        # Here, we are going to concatinate a 1x1 vector containing the value \n",
        "        # of 1 with a 1x1 vector containing the feature value with the result \n",
        "        # being a 1x2 vector.\n",
        "        #\n",
        "        # After the concatination, our 1x2 vector resembles the below, if our\n",
        "        # feature_value = 3:\n",
        "        #\n",
        "        #    x = [ 1 3 ]\n",
        "        #\n",
        "        vector_one = np.ones(1)\n",
        "        vector_feature = np.array(feature_value)\n",
        "        \n",
        "        x = np.concatenate((vector_one, vector_feature), axis = 0)\n",
        "        \n",
        "        # Finally, we multiply the vector x with our two theta values and\n",
        "        # assign it to h[i]:\n",
        "        #\n",
        "        # h[i] = [ theta1 theta2 ] * [ 1 feature ]\n",
        "        #\n",
        "        h[i] = float(np.matmul(theta, x))\n",
        "    \n",
        "    \n",
        "    # Here, we have a vector (h) with our predictions with a size of \n",
        "    # num_features x 1 (rows x columns). we need to reshape the vector so it \n",
        "    # matches the same number of rows as our DataFrame, X.\n",
        "    #\n",
        "    # TODO: Why do we need to reshape?\n",
        "    #h = h.reshape(num_features)\n",
        "    \n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FlSz41X0sSx",
        "colab_type": "text"
      },
      "source": [
        "We can choose good theta values by using the *Cost Function* denoted as $J(\\theta_{0}, \\theta_{1})$ where  $\\theta_{0}$, and $\\theta_{1}$ points on the $x$,$y$ axis and $J(\\theta_{0}, \\theta_{1})$ is *z*. This is also called the *Squared Error Function* which is the most commonly used for linear regression problems. Here, we want to get the results of our cost function as close to zero as possible by trying different values for $\\theta _{0}$ and $\\theta _{1}$.\n",
        "\n",
        "> $\\large J( \\theta _{0} ,\\ \\theta _{1}) =\\frac{1}{2m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{( i)}\\right) -y^{( i)}\\right)^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZtjTK-0tj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(theta, X, y):\n",
        "  m = len(y)\n",
        "  # Perform matrix multiplication between our feature set X and theta values.\n",
        "  predictions = hypothesis(theta, X)\n",
        "  # Compute the cost of the predictions\n",
        "  cost = (1/2*m) + np.sum(np.square(predictions - y))\n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNVDoV-Kypjm",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "What *Gradient Descent* algorithm does is *simultaneously* compute values for $\\theta_{0}$ and $\\theta_{1}$. What is meant by *simultaneously* is represented in the pseudo code below where $\\theta_{0}$ and $\\theta_{1}$ are assigned new values at the same time. In other words, if $\\theta_{0}$ was set ($\\theta_{0} :=$ *temp0*) *before* temp1 was set (*temp1* $:= \\theta_{1}-\\alpha\\frac{\\partial}{\\partial\\theta_{1}}J(\\theta_{0},\\theta_{1})$) then it would affect the results of temp1 and yield incorrect results. We want to repeat this series of steps until we reach *convergence* or $\\theta_{0}$ and $\\theta_{1}$ are at their minimum.\n",
        "\n",
        ">*repeat until convergence {* \n",
        "\n",
        ">$temp 0:= \\theta_{0}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)$\n",
        "\n",
        ">$temp1 := \\theta_{1}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)\\cdot x^{(i)}$\n",
        "\n",
        ">$\\theta_{0} := temp0$\n",
        "\n",
        ">$\\theta_{1} := temp1$\n",
        "\n",
        ">*}* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PzzJB86cP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stochastic Gradient Descent Algorithm - Performs Gradient Descent.\n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     alpha: The learning rate.\n",
        "#     iterations: The number of iterations to perform.\n",
        "#     X: The feature set.\n",
        "#     y: The target variable set.\n",
        "def gradient_descent(theta, alpha, X, y):\n",
        "    m = len(y)\n",
        "    prev_cost = 0\n",
        "    converged = False\n",
        "    report = []\n",
        "    min_theta = theta\n",
        "    i = 1\n",
        "\n",
        "    while(not converged):\n",
        "        predictions = hypothesis(theta, X) #np.dot(X, theta)\n",
        "        loss = predictions - y\n",
        "        # avg cost per example (the 2 in 2*m doesn't really matter here.\n",
        "        # But to be consistent with the gradient, I include it)\n",
        "        cost = np.sum(loss ** 2) / (2 * m)\n",
        "        \n",
        "        if (cost == prev_cost):\n",
        "          converged = True\n",
        "        else:\n",
        "          prev_cost = cost\n",
        "          \n",
        "        # avg gradient per example\n",
        "        gradient = np.dot(X.T, loss) / m\n",
        "        # update\n",
        "        theta = theta - alpha * gradient\n",
        "        \n",
        "        min_theta = theta[len(theta) - 1]\n",
        "        \n",
        "        if(i % 10 == 0 or converged):\n",
        "          report.append([converged, i, cost, min_theta[0], min_theta[1]])\n",
        "          \n",
        "        i = i + 1\n",
        "        \n",
        "    df_report = pd.DataFrame(report, columns = [ 'Converged', 'Iteration', 'Cost', 'Theta0', 'Theta1' ]);\n",
        "\n",
        "    return min_theta, df_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_J5gBlV6aA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = 2 * np.random.rand(100,1)\n",
        "y = 4 +3 * X+np.random.randn(100,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av-Oshlx6cPa",
        "colab_type": "code",
        "outputId": "a4dcf494-37a4-4d95-c9bf-a582b81112b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tSfsgQE-1rv",
        "colab_type": "code",
        "outputId": "7c1153a3-51d0-4d82-ae9f-4092e0822bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "theta = np.random.randn(2)\n",
        "learning_rate = 0.1\n",
        "\n",
        "theta, report = gradient_descent(theta, learning_rate, X, y)\n",
        "\n",
        "print(f\"theta0 = {theta[0]}\")\n",
        "print(f\"theta1 = {theta[1]}\")\n",
        "print()\n",
        "report"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "theta0 = 4.614554602263096\n",
            "theta1 = 2.494975905137514\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Converged</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Theta0</th>\n",
              "      <th>Theta1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>0.674484</td>\n",
              "      <td>4.385195</td>\n",
              "      <td>2.265616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>20</td>\n",
              "      <td>0.533460</td>\n",
              "      <td>4.597289</td>\n",
              "      <td>2.477710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>30</td>\n",
              "      <td>0.535871</td>\n",
              "      <td>4.613255</td>\n",
              "      <td>2.493676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>40</td>\n",
              "      <td>0.536126</td>\n",
              "      <td>4.614457</td>\n",
              "      <td>2.494878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>50</td>\n",
              "      <td>0.536146</td>\n",
              "      <td>4.614547</td>\n",
              "      <td>2.494969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>60</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614554</td>\n",
              "      <td>2.494975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>70</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>80</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>90</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>100</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>110</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>120</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>130</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>True</td>\n",
              "      <td>136</td>\n",
              "      <td>0.536148</td>\n",
              "      <td>4.614555</td>\n",
              "      <td>2.494976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Converged  Iteration      Cost    Theta0    Theta1\n",
              "0       False         10  0.674484  4.385195  2.265616\n",
              "1       False         20  0.533460  4.597289  2.477710\n",
              "2       False         30  0.535871  4.613255  2.493676\n",
              "3       False         40  0.536126  4.614457  2.494878\n",
              "4       False         50  0.536146  4.614547  2.494969\n",
              "5       False         60  0.536148  4.614554  2.494975\n",
              "6       False         70  0.536148  4.614555  2.494976\n",
              "7       False         80  0.536148  4.614555  2.494976\n",
              "8       False         90  0.536148  4.614555  2.494976\n",
              "9       False        100  0.536148  4.614555  2.494976\n",
              "10      False        110  0.536148  4.614555  2.494976\n",
              "11      False        120  0.536148  4.614555  2.494976\n",
              "12      False        130  0.536148  4.614555  2.494976\n",
              "13       True        136  0.536148  4.614555  2.494976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mliPwzpQgnpc",
        "colab_type": "code",
        "outputId": "bdbcf733-62e6-4aa5-bded-753606a1bf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "training_predictions = hypothesis(theta, X)\n",
        "\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.plot(X, training_predictions)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxCAiIhH/Bdz0oaUIyC3sAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}