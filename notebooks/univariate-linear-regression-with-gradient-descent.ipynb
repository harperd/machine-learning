{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "univariate-linear-regression-with-gradient-descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/notebooks/univariate-linear-regression-with-gradient-descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5PT6bd4V65",
        "colab_type": "text"
      },
      "source": [
        "# Univariate Linear Regression and Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0aXI4RCl7E",
        "colab_type": "text"
      },
      "source": [
        "## Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kq34XhwCpyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NumPy adds support for large, multi-dimensional arrays and matrices, along with a large collection \n",
        "# of high-level mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib is a plotting library for the Python programming language and its numerical mathematics \n",
        "# extension NumPy. It provides an object-oriented API for embedding plots into applications using \n",
        "# general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Pandas is a software library for data manipulation and analysis. In particular, it offers data \n",
        "# structures and operations for manipulating numerical tables and time series.\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zek8oIAP5YQH",
        "colab_type": "text"
      },
      "source": [
        "# Hypothesis Function\n",
        "\n",
        "In machine learning, a *hypothesis* function is used to predict outcomes or $y$ values. Below is the univariate linear regression hypothesis function where theta ($\\theta$) can represent any two numbers and $h_\\theta(x)$ or $y$ is our *prediction*. We just have to figure out what those two numbers are that allow the function to best intersect our data or features. It's a simple linear equation but finding the best theta values is where the challenge lies.\n",
        "\n",
        "> $h_{\\theta }( x) =\\theta _{0} \\ +\\ \\theta _{1} x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFuhgcny3XzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hypothesis Function - This function will compute predictions for all features. \n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     X: A DataFrame containing the features to create predictions against.\n",
        "def hypothesis(theta, X):\n",
        "    # Here, X is a Pandas DataFrame containing all of our data.\n",
        "    # X.shape returns tuple of the shape's dimentions in rows x columns.\n",
        "    # Therefore, X.shape[0] will get us the number of rows, or features.\n",
        "    num_features = len(X)\n",
        "    \n",
        "    # numpy.ones returns a new array of given shape, filled with ones.\n",
        "    # Here, we want a new array (vector) of size num_features x 1 (rows x columns).\n",
        "    h = np.ones((num_features, 1))\n",
        "    \n",
        "    # Loop through each feature (x) in our data set.\n",
        "    #\n",
        "    # TODO: Perform this in a more optimal manner using matrix multiplication\n",
        "    #       against the entire feature set, X.\n",
        "    for i in range(0, num_features):\n",
        "        # Get the next feature value.\n",
        "        feature_value = X[i]\n",
        "        \n",
        "        # Here, we are going to concatinate a 1x1 vector containing the value \n",
        "        # of 1 with a 1x1 vector containing the feature value with the result \n",
        "        # being a 1x2 vector.\n",
        "        #\n",
        "        # After the concatination, our 1x2 vector resembles the below, if our\n",
        "        # feature_value = 3:\n",
        "        #\n",
        "        #    x = [ 1 3 ]\n",
        "        #\n",
        "        vector_one = np.ones(1)\n",
        "        vector_feature = np.array(feature_value)\n",
        "        \n",
        "        x = np.concatenate((vector_one, vector_feature), axis = 0)\n",
        "        \n",
        "        # Finally, we multiply the vector x with our two theta values and\n",
        "        # assign it to h[i]:\n",
        "        #\n",
        "        # h[i] = [ theta1 theta2 ] * [ 1 feature ]\n",
        "        #\n",
        "        h[i] = float(np.matmul(theta, x))\n",
        "    \n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FlSz41X0sSx",
        "colab_type": "text"
      },
      "source": [
        "We can choose good theta values by using the *Cost Function* denoted as $J(\\theta_{0}, \\theta_{1})$ where  $\\theta_{0}$, and $\\theta_{1}$ points on the $x$,$y$ axis and $J(\\theta_{0}, \\theta_{1})$ is *z*. This is also called the *Squared Error Function* which is the most commonly used for linear regression problems. Here, we want to get the results of our cost function as close to zero as possible by trying different values for $\\theta _{0}$ and $\\theta _{1}$.\n",
        "\n",
        "> $\\large J( \\theta _{0} ,\\ \\theta _{1}) =\\frac{1}{2m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{( i)}\\right) -y^{( i)}\\right)^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZtjTK-0tj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(theta, X, y):\n",
        "  # Get the number of examples\n",
        "  m = len(y)\n",
        "  \n",
        "  # Perform matrix multiplication between our feature set X and theta values.\n",
        "  predictions = hypothesis(theta, X)\n",
        "  \n",
        "  # Compute the cost of the predictions\n",
        "  cost = (1/2*m) + np.sum(np.square(predictions - y))\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNVDoV-Kypjm",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "What *Gradient Descent* algorithm does is *simultaneously* compute values for $\\theta_{0}$ and $\\theta_{1}$. What is meant by *simultaneously* is represented in the pseudo code below where $\\theta_{0}$ and $\\theta_{1}$ are assigned new values at the same time. In other words, if $\\theta_{0}$ was set ($\\theta_{0} :=$ *temp0*) *before* temp1 was set (*temp1* $:= \\theta_{1}-\\alpha\\frac{\\partial}{\\partial\\theta_{1}}J(\\theta_{0},\\theta_{1})$) then it would affect the results of temp1 and yield incorrect results. We want to repeat this series of steps until we reach *convergence* or $\\theta_{0}$ and $\\theta_{1}$ are at their minimum.\n",
        "\n",
        ">*repeat until convergence {* \n",
        "\n",
        ">$temp 0:= \\theta_{0}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)$\n",
        "\n",
        ">$temp1 := \\theta_{1}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)\\cdot x^{(i)}$\n",
        "\n",
        ">$\\theta_{0} := temp0$\n",
        "\n",
        ">$\\theta_{1} := temp1$\n",
        "\n",
        ">*}* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PzzJB86cP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to see if we have converged to the local minimum.\n",
        "def is_converged(c_theta, p_theta):\n",
        "  return c_theta[0] == p_theta[0] and c_theta[1] == p_theta[1]\n",
        "\n",
        "# Stochastic Gradient Descent Algorithm - Performs Gradient Descent.\n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     alpha: The learning rate.\n",
        "#     iterations: The number of iterations to perform.\n",
        "#     X: The feature set.\n",
        "#     y: The target variable set.\n",
        "def gradient_descent(theta, alpha, X, y):\n",
        "    # Get the number of examples\n",
        "    m = len(y)\n",
        "\n",
        "    converged = False\n",
        "    report = []\n",
        "    prev_theta = theta\n",
        "    optimal_theta = theta\n",
        "    iteration = 1\n",
        "\n",
        "    # Keep trying until we have converged at the local minimum.\n",
        "    while(not converged):\n",
        "        # Try a prediction with current theta values.\n",
        "        predictions = hypothesis(theta, X)\n",
        "        \n",
        "        # Compute the cost i.e. J(theta0, theta1)\n",
        "        cost = compute_cost(theta, X, y)\n",
        "        \n",
        "        # Compute the average gradient per example.\n",
        "        loss = predictions - y\n",
        "        gradient = np.dot(X.T, loss) / m\n",
        "        \n",
        "        # Update theta\n",
        "        theta = ( theta - alpha * gradient )\n",
        "        theta = theta[len(theta) - 1]\n",
        "        \n",
        "        # Check to see if we have converged or not.\n",
        "        converged = is_converged(theta, optimal_theta)\n",
        "        \n",
        "        # Set the optimal theta to the current theta.\n",
        "        optimal_theta = theta\n",
        "        \n",
        "        # Get data to report\n",
        "        if(iteration % 20 == 0 or converged):\n",
        "          report.append([ \n",
        "              'Converged -->' if converged else '', \n",
        "              iteration, \n",
        "              cost, \n",
        "              optimal_theta[0], \n",
        "              optimal_theta[1]])\n",
        "\n",
        "        iteration = iteration + 1\n",
        "        \n",
        "    # Convert our report data to a Pandas DataFrame for better rendering.\n",
        "    df_report = pd.DataFrame(\n",
        "        report, \n",
        "        columns = [ 'Converged', 'Iteration', 'Cost', 'Theta0', 'Theta1' ]);\n",
        "\n",
        "    return optimal_theta, df_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_J5gBlV6aA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "1bec9390-8014-4aed-ebf7-c504ca3d2447"
      },
      "source": [
        "# Generate random samples\n",
        "X = 2 * np.random.rand(100,1)\n",
        "y = 4 +3 * X+np.random.randn(100,1)\n",
        "\n",
        "# Plot our random samples\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQGAAABQQGAAABQQGAEDB/wPCzcFLhkxGDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tSfsgQE-1rv",
        "colab_type": "code",
        "outputId": "66915239-59c3-4d95-9540-e70923fc027d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# Initialize theta and set our learning rate.\n",
        "theta = [ 0, 0 ]\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Perform Gradient Descent\n",
        "theta, report = gradient_descent(theta, learning_rate, X, y)\n",
        "\n",
        "# Show the Gradent Descent report\n",
        "pd.option_context('display.float_format', '{:,.20f}'.format)\n",
        "report"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Converged</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Theta0</th>\n",
              "      <th>Theta1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>20</td>\n",
              "      <td>201.60802657965459161460</td>\n",
              "      <td>3.46275343149427428102</td>\n",
              "      <td>3.46275343149427428102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>40</td>\n",
              "      <td>200.96417571294682602456</td>\n",
              "      <td>3.47869652995652822725</td>\n",
              "      <td>3.47869652995652822725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>60</td>\n",
              "      <td>200.96209029324523953619</td>\n",
              "      <td>3.47876993465992612187</td>\n",
              "      <td>3.47876993465992612187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>80</td>\n",
              "      <td>200.96208071025549202204</td>\n",
              "      <td>3.47877027262751070680</td>\n",
              "      <td>3.47877027262751070680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>100</td>\n",
              "      <td>200.96208066613422715818</td>\n",
              "      <td>3.47877027418356998822</td>\n",
              "      <td>3.47877027418356998822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>120</td>\n",
              "      <td>200.96208066593106877917</td>\n",
              "      <td>3.47877027419073447945</td>\n",
              "      <td>3.47877027419073447945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Converged --&gt;</td>\n",
              "      <td>134</td>\n",
              "      <td>200.96208066593015928447</td>\n",
              "      <td>3.47877027419076689796</td>\n",
              "      <td>3.47877027419076689796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Converged  Iteration  ...                 Theta0                 Theta1\n",
              "0                        20  ... 3.46275343149427428102 3.46275343149427428102\n",
              "1                        40  ... 3.47869652995652822725 3.47869652995652822725\n",
              "2                        60  ... 3.47876993465992612187 3.47876993465992612187\n",
              "3                        80  ... 3.47877027262751070680 3.47877027262751070680\n",
              "4                       100  ... 3.47877027418356998822 3.47877027418356998822\n",
              "5                       120  ... 3.47877027419073447945 3.47877027419073447945\n",
              "6  Converged -->        134  ... 3.47877027419076689796 3.47877027419076689796\n",
              "\n",
              "[7 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP3l3FXScCQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "e9f54c7d-4138-4f64-92c7-2da0f22d14e7"
      },
      "source": [
        "# Execute our hypothesis with our optimal theta values.\n",
        "training_predictions = hypothesis(theta, X)\n",
        "\n",
        "# Plot the results.\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.plot(X, training_predictions)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nifOZ5nMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}