{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "univariate-linear-regression-with-gradient-descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/notebooks/univariate-linear-regression-with-gradient-descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5PT6bd4V65",
        "colab_type": "text"
      },
      "source": [
        "# Univariate Linear Regression and Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0aXI4RCl7E",
        "colab_type": "text"
      },
      "source": [
        "## Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kq34XhwCpyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NumPy adds support for large, multi-dimensional arrays and matrices, along with a large collection \n",
        "# of high-level mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib is a plotting library for the Python programming language and its numerical mathematics \n",
        "# extension NumPy. It provides an object-oriented API for embedding plots into applications using \n",
        "# general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Pandas is a software library for data manipulation and analysis. In particular, it offers data \n",
        "# structures and operations for manipulating numerical tables and time series.\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zek8oIAP5YQH",
        "colab_type": "text"
      },
      "source": [
        "# Hypothesis Function\n",
        "\n",
        "In machine learning, a *hypothesis* function is used to predict outcomes or $y$ values. Below is the univariate linear regression hypothesis function where theta ($\\theta$) can represent any two numbers and $h_\\theta(x)$ or $y$ is our *prediction*. We just have to figure out what those two numbers are that allow the function to best intersect our data or features. It's a simple linear equation but finding the best theta values is where the challenge lies.\n",
        "\n",
        "> $h_{\\theta }( x) =\\theta _{0} \\ +\\ \\theta _{1} x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFuhgcny3XzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hypothesis Function - This function will compute predictions for all features. \n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     X: A DataFrame containing the features to create predictions against.\n",
        "def hypothesis(theta, X):\n",
        "    # Here, X is a Pandas DataFrame containing all of our data.\n",
        "    # X.shape returns tuple of the shape's dimentions in rows x columns.\n",
        "    # Therefore, X.shape[0] will get us the number of rows, or features.\n",
        "    num_features = len(X)\n",
        "    \n",
        "    # numpy.ones returns a new array of given shape, filled with ones.\n",
        "    # Here, we want a new array (vector) of size num_features x 1 (rows x columns).\n",
        "    h = np.ones((num_features, 1))\n",
        "    \n",
        "    # Loop through each feature (x) in our data set.\n",
        "    #\n",
        "    # TODO: Perform this in a more optimal manner using matrix multiplication\n",
        "    #       against the entire feature set, X.\n",
        "    for i in range(0, num_features):\n",
        "        # Get the next feature value.\n",
        "        feature_value = X[i]\n",
        "        \n",
        "        # Here, we are going to concatinate a 1x1 vector containing the value \n",
        "        # of 1 with a 1x1 vector containing the feature value with the result \n",
        "        # being a 1x2 vector.\n",
        "        #\n",
        "        # After the concatination, our 1x2 vector resembles the below, if our\n",
        "        # feature_value = 3:\n",
        "        #\n",
        "        #    x = [ 1 3 ]\n",
        "        #\n",
        "        vector_one = np.ones(1)\n",
        "        vector_feature = np.array(feature_value)\n",
        "        \n",
        "        x = np.concatenate((vector_one, vector_feature), axis = 0)\n",
        "        \n",
        "        # Finally, we multiply the vector x with our two theta values and\n",
        "        # assign it to h[i]:\n",
        "        #\n",
        "        # h[i] = [ theta1 theta2 ] * [ 1 feature ]\n",
        "        #\n",
        "        h[i] = float(np.matmul(theta, x))\n",
        "    \n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FlSz41X0sSx",
        "colab_type": "text"
      },
      "source": [
        "We can choose good theta values by using the *Cost Function* denoted as $J(\\theta_{0}, \\theta_{1})$ where  $\\theta_{0}$, and $\\theta_{1}$ points on the $x$,$y$ axis and $J(\\theta_{0}, \\theta_{1})$ is *z*. This is also called the *Squared Error Function* which is the most commonly used for linear regression problems. Here, we want to get the results of our cost function as close to zero as possible by trying different values for $\\theta _{0}$ and $\\theta _{1}$.\n",
        "\n",
        "> $\\large J( \\theta _{0} ,\\ \\theta _{1}) =\\frac{1}{2m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{( i)}\\right) -y^{( i)}\\right)^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZtjTK-0tj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(theta, X, y):\n",
        "  # Get the number of examples\n",
        "  m = len(y)\n",
        "  \n",
        "  # Perform matrix multiplication between our feature set X and theta values.\n",
        "  predictions = hypothesis(theta, X)\n",
        "  \n",
        "  # Compute the cost of the predictions\n",
        "  cost = (1/2*m) + np.sum(np.square(predictions - y))\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNVDoV-Kypjm",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "What *Gradient Descent* algorithm does is *simultaneously* compute values for $\\theta_{0}$ and $\\theta_{1}$. What is meant by *simultaneously* is represented in the pseudo code below where $\\theta_{0}$ and $\\theta_{1}$ are assigned new values at the same time. In other words, if $\\theta_{0}$ was set ($\\theta_{0} :=$ *temp0*) *before* temp1 was set (*temp1* $:= \\theta_{1}-\\alpha\\frac{\\partial}{\\partial\\theta_{1}}J(\\theta_{0},\\theta_{1})$) then it would affect the results of temp1 and yield incorrect results. We want to repeat this series of steps until we reach *convergence* or $\\theta_{0}$ and $\\theta_{1}$ are at their minimum.\n",
        "\n",
        ">*repeat until convergence {* \n",
        "\n",
        ">$temp 0:= \\theta_{0}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)$\n",
        "\n",
        ">$temp1 := \\theta_{1}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)\\cdot x^{(i)}$\n",
        "\n",
        ">$\\theta_{0} := temp0$\n",
        "\n",
        ">$\\theta_{1} := temp1$\n",
        "\n",
        ">*}* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_MYB6CYTC2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_converged(theta, cur_theta):\n",
        "  prev_theta0 = theta[len(theta)-1][0]\n",
        "  prev_theta1 = theta[len(theta)-1][1]\n",
        "  cur_theta0 = cur_theta[0]\n",
        "  cur_theta1 = cur_theta[1]\n",
        "  return prev_theta0 == cur_theta0 and prev_theta1 == cur_theta1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PzzJB86cP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stochastic Gradient Descent Algorithm - Performs Gradient Descent.\n",
        "#\n",
        "# Parameters\n",
        "#     theta: The two theta values as an array [ theta1, theta2 ]\n",
        "#     alpha: The learning rate.\n",
        "#     iterations: The number of iterations to perform.\n",
        "#     X: The feature set.\n",
        "#     y: The target variable set.\n",
        "def gradient_descent(theta, alpha, X, y):\n",
        "    # Get the number of examples\n",
        "    m = len(y)\n",
        "\n",
        "    converged = False\n",
        "    report = []\n",
        "    prev_theta = theta\n",
        "    i = 1\n",
        "\n",
        "    # Keep trying until we have converged at the local minimum.\n",
        "    while(not converged):\n",
        "        # Try a prediction with current theta values.\n",
        "        predictions = hypothesis(theta, X)\n",
        "        \n",
        "        # Compute the cost i.e. J(theta0, theta1)\n",
        "        cost = compute_cost(theta, X, y)\n",
        "        \n",
        "        # Compute the average gradient per example.\n",
        "        loss = predictions - y\n",
        "        gradient = np.dot(X.T, loss) / m\n",
        "        \n",
        "        # Update theta\n",
        "        theta = theta - alpha * gradient\n",
        "        \n",
        "        converged = is_converged(theta, prev_theta)\n",
        "     \n",
        "        # Get data to report\n",
        "        if(i % 10 == 0 or converged):\n",
        "          report.append([ \n",
        "              '*' if converged else '', \n",
        "              i, \n",
        "              cost, \n",
        "              min_theta[0], \n",
        "              min_theta[1]])\n",
        "          \n",
        "        prev_theta = theta[len(theta) - 1]\n",
        "        i = i + 1\n",
        "        \n",
        "    df_report = pd.DataFrame(\n",
        "        report, \n",
        "        columns = [ 'Converged', 'Iteration', 'Cost', 'Theta0', 'Theta1' ]);\n",
        "\n",
        "    return min_theta, df_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_J5gBlV6aA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = 2 * np.random.rand(100,1)\n",
        "y = 4 +3 * X+np.random.randn(100,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av-Oshlx6cPa",
        "colab_type": "code",
        "outputId": "4141f4c5-c606-423c-98ea-0e525169a3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tSfsgQE-1rv",
        "colab_type": "code",
        "outputId": "a0c0006c-cff9-4795-85b8-dfcb9b282baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "theta = np.random.randn(2)\n",
        "learning_rate = 0.1\n",
        "\n",
        "theta, report = gradient_descent(theta, learning_rate, X, y)\n",
        "\n",
        "print(f\"theta0 = {theta[0]}\")\n",
        "print(f\"theta1 = {theta[1]}\")\n",
        "print()\n",
        "\n",
        "pd.options.display.float_format = '{:,.20f}'.format\n",
        "report"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "theta0 = 4.2704116032366715\n",
            "theta1 = 2.7806628286486106\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Converged</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Theta0</th>\n",
              "      <th>Theta1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>10</td>\n",
              "      <td>145.82259393918556611425</td>\n",
              "      <td>4.10655983093447218835</td>\n",
              "      <td>2.61681105634640953639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>20</td>\n",
              "      <td>126.62439398633313203391</td>\n",
              "      <td>4.26289841750314124624</td>\n",
              "      <td>2.77314964291507948246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>30</td>\n",
              "      <td>126.77726780209071932859</td>\n",
              "      <td>4.27006709698523856389</td>\n",
              "      <td>2.78031832239717768829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>40</td>\n",
              "      <td>126.78644991918049811375</td>\n",
              "      <td>4.27039580640141647194</td>\n",
              "      <td>2.78064703181335559634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>50</td>\n",
              "      <td>126.78687551924818421867</td>\n",
              "      <td>4.27041087889566739477</td>\n",
              "      <td>2.78066210430760785144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>60</td>\n",
              "      <td>126.78689504412605515427</td>\n",
              "      <td>4.27041157002306359658</td>\n",
              "      <td>2.78066279543500405325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>70</td>\n",
              "      <td>126.78689593943123270492</td>\n",
              "      <td>4.27041160171370925980</td>\n",
              "      <td>2.78066282712564971646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>80</td>\n",
              "      <td>126.78689598048426034893</td>\n",
              "      <td>4.27041160316683932052</td>\n",
              "      <td>2.78066282857877800083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>90</td>\n",
              "      <td>126.78689598236665858622</td>\n",
              "      <td>4.27041160323347046557</td>\n",
              "      <td>2.78066282864540914588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>100</td>\n",
              "      <td>126.78689598245297531776</td>\n",
              "      <td>4.27041160323652579933</td>\n",
              "      <td>2.78066282864846403555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>110</td>\n",
              "      <td>126.78689598245691172451</td>\n",
              "      <td>4.27041160323666613152</td>\n",
              "      <td>2.78066282864860392365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>*</td>\n",
              "      <td>119</td>\n",
              "      <td>126.78689598245709646562</td>\n",
              "      <td>4.27041160323667146059</td>\n",
              "      <td>2.78066282864861058499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Converged  Iteration  ...                 Theta0                 Theta1\n",
              "0                    10  ... 4.10655983093447218835 2.61681105634640953639\n",
              "1                    20  ... 4.26289841750314124624 2.77314964291507948246\n",
              "2                    30  ... 4.27006709698523856389 2.78031832239717768829\n",
              "3                    40  ... 4.27039580640141647194 2.78064703181335559634\n",
              "4                    50  ... 4.27041087889566739477 2.78066210430760785144\n",
              "5                    60  ... 4.27041157002306359658 2.78066279543500405325\n",
              "6                    70  ... 4.27041160171370925980 2.78066282712564971646\n",
              "7                    80  ... 4.27041160316683932052 2.78066282857877800083\n",
              "8                    90  ... 4.27041160323347046557 2.78066282864540914588\n",
              "9                   100  ... 4.27041160323652579933 2.78066282864846403555\n",
              "10                  110  ... 4.27041160323666613152 2.78066282864860392365\n",
              "11         *        119  ... 4.27041160323667146059 2.78066282864861058499\n",
              "\n",
              "[12 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mliPwzpQgnpc",
        "colab_type": "code",
        "outputId": "0c99a58a-ec37-4371-e191-a75373baf040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "training_predictions = hypothesis(theta, X)\n",
        "\n",
        "plt.plot(X,y,'b.')\n",
        "plt.xlabel(\"$x$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.plot(X, training_predictions)\n",
        "_ =plt.axis([0,2,0,15])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJBAYgAAJJAYAAAJ/x/OhkT81sOm4AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}