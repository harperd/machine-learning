{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiclass-logistic-regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/notebooks/multiclass-logistic-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMu0-xrhFSTR",
        "colab_type": "text"
      },
      "source": [
        "# Multiclass Logistic Regression\n",
        "\n",
        "Use logistic regression to recognize hand-written digits (0 to 9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2GQSOFcC6Od",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIbeQTjIFLV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import pandas as pd\n",
        "import google.colab as colab\n",
        "import scipy.optimize as opt\n",
        "import io\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Allow saving our graphs in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "style.use('dark_background')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3ZqURKnCgsa",
        "colab_type": "text"
      },
      "source": [
        "## Read Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yto5KquyIjpU",
        "colab_type": "code",
        "outputId": "5546fc0d-d994-486d-97dc-772be68b750a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "mat_file = colab.files.upload()\n",
        "!ls -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ade7298-5def-45b0-9e6f-6313a27ddbf8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8ade7298-5def-45b0-9e6f-6313a27ddbf8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ex3data1.mat to ex3data1.mat\n",
            "total 7340\n",
            "-rw-r--r-- 1 root root 7511764 Aug 10 17:54 ex3data1.mat\n",
            "drwxr-xr-x 1 root root    4096 Aug  2 16:06 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh72WN5fGNN8",
        "colab_type": "code",
        "outputId": "cc03cf78-88cd-4f9e-d7ec-3192e454efcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "mat_data = loadmat('ex3data1.mat')\n",
        "mat_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " '__globals__': [],\n",
              " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
              " '__version__': '1.0',\n",
              " 'y': array([[10],\n",
              "        [10],\n",
              "        [10],\n",
              "        ...,\n",
              "        [ 9],\n",
              "        [ 9],\n",
              "        [ 9]], dtype=uint8)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r2DqgKcJRXI",
        "colab_type": "code",
        "outputId": "d94be958-ebea-42c3-d323-b351d8854311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X = mat_data['X']\n",
        "# Add bias column\n",
        "X = np.hstack((np.ones(X.shape[0])[:, np.newaxis], X))\n",
        "\n",
        "y = mat_data['y']\n",
        "theta = np.array(np.zeros(X.shape[1]), ndmin = 2)\n",
        "\n",
        "print(f'X Shape: {X.shape}')\n",
        "print(f'y Shape: {y.shape}')\n",
        "print(f'Theta Shape: {theta.shape}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape: (5000, 401)\n",
            "y Shape: (5000, 1)\n",
            "Theta Shape: (1, 401)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3JyiN6oO92O",
        "colab_type": "text"
      },
      "source": [
        "![Hand written numbers](https://github.com/harperd/machine-learning/blob/master/images/ex3-1.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DagnmOHRJWaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / ( 1 + np.exp(-z) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV1LSYsXPX8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_hypothesis(theta, X):\n",
        "  # Compute our hypothesis\n",
        "  z = X @ theta.T\n",
        "  \n",
        "  # Scale our hypothesis using Sigmoid.\n",
        "  # Here, if the parameter is zero then the sigmoid value will be 0.5.\n",
        "  h = sigmoid(z)\n",
        "  \n",
        "  return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-HfxOfAPcW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(theta, X, y, alpha):\n",
        "  # Fix for minimize function\n",
        "  theta = np.array(theta, ndmin = 2)\n",
        "  X = np.array(X, ndmin = 2)\n",
        "  y = np.array(y, ndmin = 2)\n",
        "  \n",
        "  # Compute our hypothesis\n",
        "  h = compute_hypothesis(theta, X)\n",
        "  \n",
        "  first = np.log(h) * -y\n",
        "  second = np.log(1 - h) * (1 - y)\n",
        "  \n",
        "  # The number of examples\n",
        "  m = len(y)\n",
        "  \n",
        "  # Implement Ridge Regression (L2 Regularization)\n",
        "  #\n",
        "  # Get all theta values except theta0 out\n",
        "  # intercept term\n",
        "  num_params = theta.shape[1]\n",
        "  params = theta[:, 1:num_params]\n",
        "  \n",
        "  # Set our lambda value\n",
        "  lamb = alpha / ( m * 2 )\n",
        "  \n",
        "  # Compute our regularization term for cost\n",
        "  reg = lamb * np.sum(params ** 2)\n",
        "  \n",
        "  # Compute our cost with regularization\n",
        "  cost = ( np.sum(first - second) / m ) + reg\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMmza1f3QjVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient(theta, X, y, alpha):\n",
        "  # Fix for minimize function\n",
        "  theta = np.array(theta, ndmin = 2)\n",
        "  X = np.array(X, ndmin = 2)\n",
        "  y = np.array(y, ndmin = 2)\n",
        "  \n",
        "  # Compute our hypothesis\n",
        "  h = compute_hypothesis(theta, X)\n",
        "\n",
        "  # Get the error\n",
        "  error = h - y\n",
        "\n",
        "  # The number of examples\n",
        "  m = len(y)\n",
        "  \n",
        "  # Set our lambda value\n",
        "  lamb = alpha / ( m * 2 )\n",
        "  \n",
        "  # Compute our regularization term for gradient descent\n",
        "  reg = 1 - (alpha * (lamb / m))\n",
        "  \n",
        "  # Calculate the gradient\n",
        "  gradient = ( theta * reg ) - ( alpha * ((error.T @ X) / m) )\n",
        "  \n",
        "  return gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlMy1eleW5eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cgrad(theta, X, y, learningRate):\n",
        "    theta = np.matrix(theta)\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    parameters = int(theta.ravel().shape[1])\n",
        "    error = sigmoid(X * theta.T) - y\n",
        "    \n",
        "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
        "    \n",
        "    # intercept gradient is not regularized\n",
        "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
        "    \n",
        "    return np.array(grad).ravel()\n",
        "  \n",
        "def ccost(theta, X, y, learningRate):\n",
        "  theta = np.matrix(theta)\n",
        "  X = np.matrix(X)\n",
        "  y = np.matrix(y)\n",
        "  first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
        "  second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
        "  reg = (learningRate / 2 * len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
        "  return np.sum(first - second) / (len(X)) + reg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVnvahignF7",
        "colab_type": "code",
        "outputId": "1f938658-6e42-4324-acef-029906f6a7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "def train_model(theta, X, y, alpha):\n",
        "  num_classes = len(np.unique(y))\n",
        "  num_params = theta.shape[1]\n",
        "  theta_min = np.ones((num_classes, num_params))\n",
        "  \n",
        "  for k in range(1, num_classes + 1):\n",
        "    print(f'Optimizing theta values for class {k}... ', end = '')\n",
        "\n",
        "    y_train = [ 1 if K[0] == k else 0 for K in y ]\n",
        "    y_train = np.array(y_train, ndmin = 2).T\n",
        "\n",
        "    result = minimize(\n",
        "        method = 'TNC',\n",
        "        fun = compute_cost, jac = compute_gradient,\n",
        "        #fun = ccost, jac = cgrad,\n",
        "        x0 = theta,\n",
        "        args = ( X, y_train, alpha ))\n",
        "\n",
        "    #result = opt.fmin_tnc(\n",
        "    #      # Initial guess.\n",
        "    #      x0 = theta,\n",
        "    #      # Objective function to be minimized.\n",
        "    #      func = compute_cost,\n",
        "    #      # Gradient of func.\n",
        "    #      fprime = compute_gradient,\n",
        "    #      # Extra arguments passed to f and fprime.\n",
        "    #      args = ( X, y_train, alpha ))\n",
        "\n",
        "    theta_min[k - 1] = result.x #result[0]\n",
        "    \n",
        "    cost = compute_cost(result.x, X, y_train, alpha)\n",
        "    \n",
        "    if(result.message):\n",
        "      print(result.message)\n",
        "    else:\n",
        "      print(f'Iterations = {result.nit}, cost = {cost}')\n",
        "  \n",
        "  return theta_min\n",
        "\n",
        "theta_min = train_model(theta, X, y, 1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizing theta values for class 1... Linear search failed\n",
            "Optimizing theta values for class 2... Linear search failed\n",
            "Optimizing theta values for class 3... Linear search failed\n",
            "Optimizing theta values for class 4... Linear search failed\n",
            "Optimizing theta values for class 5... Linear search failed\n",
            "Optimizing theta values for class 6... Linear search failed\n",
            "Optimizing theta values for class 7... Linear search failed\n",
            "Optimizing theta values for class 8... Linear search failed\n",
            "Optimizing theta values for class 9... Linear search failed\n",
            "Optimizing theta values for class 10... Linear search failed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op70V9ty52Al",
        "colab_type": "code",
        "outputId": "c28faba7-5e2a-4c82-98e3-79bd80bc89ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_predictions(theta, X):\n",
        "  # Compute our hypothesis\n",
        "  h = compute_hypothesis(theta, X)\n",
        "  \n",
        "  # Get the index of each max probability for each\n",
        "  # of the 5k examples where index number is the \n",
        "  # classifier.\n",
        "  h = ( np.argmax(h, axis = 1) ) + 1\n",
        "  \n",
        "  return h\n",
        "\n",
        "def compute_accuracy(predictions, y):\n",
        "  # Get the correct predictions where correct is 1 and\n",
        "  # incorrect is 0.\n",
        "  correct = [ \n",
        "      1 if p_val == y_val else 0 \n",
        "      # The purpose of zip() is to map the similar index of multiple \n",
        "      # containers so that they can be used just using as single entity.\n",
        "      for (p_val, y_val) in zip(predictions, y)\n",
        "  ]\n",
        "  \n",
        "  # Calculate the overall accuracy.\n",
        "  accuracy = sum(correct) / len(correct)\n",
        "  \n",
        "  return accuracy\n",
        "\n",
        "h = make_predictions(theta_min, X)\n",
        "accuracy = compute_accuracy(h, y)\n",
        "\n",
        "print(f'Model accuracy: {accuracy * 100}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy: 10.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}