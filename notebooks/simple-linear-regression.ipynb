{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple-linear-regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harperd/machine-learning/blob/master/notebooks/simple-linear-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoS9ypJlamoe",
        "colab_type": "text"
      },
      "source": [
        "# Simple Linear Regression\n",
        "\n",
        "Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities. You need to figure out what the expected profit of a new food truck might be given only the population of the city that it would be placed in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZw8cwAagrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "08dbb9d2-48af-4fc1-f695-f4097e4a4ee4"
      },
      "source": [
        "# NumPy adds support for large, multi-dimensional arrays and matrices, along with a large collection \n",
        "# of high-level mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib is a plotting library for the Python programming language and its numerical mathematics \n",
        "# extension NumPy. It provides an object-oriented API for embedding plots into applications using \n",
        "# general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Allow saving our graphs in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install plotly\n",
        "!pip install plotly --upgrade\n",
        "\n",
        "# KzwdDa6shFfpQaAwSITY\n",
        "\n",
        "# Pandas is a software library for data manipulation and analysis. In particular, it offers data \n",
        "# structures and operations for manipulating numerical tables and time series.\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (3.6.1)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly) (2.21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.12.0)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly) (4.4.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2.8)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.3.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.4.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (0.2.0)\n",
            "Collecting plotly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/75/3982bac5076d0ce6d23103c03840fcaec90c533409f9d82c19f54512a38a/plotly-3.10.0-py2.py3-none-any.whl (41.5MB)\n",
            "\u001b[K     |████████████████████████████████| 41.5MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from plotly) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from plotly) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly) (0.2.0)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 3.6.1\n",
            "    Uninstalling plotly-3.6.1:\n",
            "      Successfully uninstalled plotly-3.6.1\n",
            "Successfully installed plotly-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF4UVfHEaj1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_raw = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/harperd/machine-learning/master/data/ex1data1.csv',\n",
        "    header = None,\n",
        "    names=[ 'Population', 'Profit' ])\n",
        "%time print(f'{len(df_raw.index)} rows read.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnmGDtjUcjpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_raw.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YCK2X25fDtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_raw.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWWtzz4bfIIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_raw.plot(kind = 'scatter', x = 'Population', y = 'Profit', figsize = (12,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQAPGxTnuJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append a bias column to the beginning\n",
        "# of the DataFrame. This will be used when computing\n",
        "# the hypothesis using matrix multiplication.\n",
        "if 'Bias' not in df_raw:\n",
        "  # Insert new column at index 0, with name Bias and\n",
        "  # a value of all ones.\n",
        "  df_raw.insert(0, 'Bias', 1)\n",
        "  \n",
        "df_raw.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U69Ud69Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set X (independent/training variable) \n",
        "# and y (dependent/target variable)\n",
        "cols = df_raw.shape[1]\n",
        "\n",
        "# Get the first two columns of our DataFrame and assign to X.\n",
        "X = df_raw.iloc[:,0:cols-1]\n",
        "\n",
        "# Get the last column of our DataFrame and assign to y.\n",
        "y = df_raw.iloc[:,cols-1:cols]\n",
        "\n",
        "# Convert from DataFrames to numpy matrices for easier\n",
        "# calculations.\n",
        "X = np.matrix(X.values)\n",
        "y = np.matrix(y.values)\n",
        "theta = np.matrix(np.array([0,0]))\n",
        "\n",
        "X.shape, theta.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jErth08NfZo-",
        "colab_type": "text"
      },
      "source": [
        "$\\large J( \\theta _{0} ,\\ \\theta _{1}) =\\frac{1}{2m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{( i)}\\right) -y^{( i)}\\right)^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIvhI6VVfVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def compute_cost(X, y, theta):\n",
        "  # h(x)\n",
        "  # Calculate predictions, h(x), with current theta values.\n",
        "  # Here we are doing matrix multiplication as \n",
        "  # X multiplied by theta transposed.\n",
        "  predictions = X * theta.T\n",
        "\n",
        "  # h(x) - y\n",
        "  # Get the error which tells us how far off our\n",
        "  # preditions are from the dependent variables.\n",
        "  error = predictions - y\n",
        "  \n",
        "  # sum( (h(x) - y)^2 )\n",
        "  # Get the sum square error.\n",
        "  sum_square_error = np.sum(np.square(error))\n",
        "  \n",
        "  # 1/2m * sum( (h(x) - y)^2 )\n",
        "  # Compute the cost.\n",
        "  m = len(y)\n",
        "  cost = sum_square_error / ( 2 * m )\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRo2_oUwsp-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Cost with a theta0 of {theta[0,0]} and theta1 of {theta[0,1]} is {compute_cost(X, y, theta)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJN7qF-mqtYX",
        "colab_type": "text"
      },
      "source": [
        "*repeat until convergence {* \n",
        "\n",
        "​\t$temp 0:= \\theta_{0}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)$\n",
        "\n",
        "​\t$temp1 := \\theta_{1}-\\alpha\\frac{1}{m}\\sum\\limits ^{m}_{i=1}\\left( h_{\\theta }\\left( x^{(i)}\\right) -y^{( i)}\\right)\\cdot x^{(i)}$\n",
        "\n",
        "​\t$\\theta_{0} := temp0$\n",
        "\n",
        "​\t$\\theta_{1} := temp1$\n",
        "\n",
        "*}* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qww9Pjkisv_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(X, y, theta, alpha):\n",
        "    temp = np.matrix(np.zeros(theta.shape))\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "    theta_history = []\n",
        "    cost = 0\n",
        "    iterations = 0\n",
        "    converged = False\n",
        "    \n",
        "    # Keep calculating new theta values until we have converged\n",
        "    # at the minimum.\n",
        "    while not converged:\n",
        "      # Calculate predictions, h(x), with current theta values.\n",
        "      predictions = X * theta.T\n",
        "\n",
        "      # Get the error which tells us how far off we are from the\n",
        "      # actual/dependent variables.\n",
        "      error = predictions - y\n",
        "\n",
        "      # Get feature data without bias column.\n",
        "      x = X[:,1]\n",
        "\n",
        "      # Calculate new theta values.\n",
        "      temp[0,0] = theta[0,0] - ( alpha * ( np.sum(error) / m ) )\n",
        "      temp[0,1] = theta[0,1] - ( alpha * ( np.sum(np.multiply(error, x)) / m ) )\n",
        "\n",
        "      theta = temp\n",
        "\n",
        "      # Compute the cost.\n",
        "      cost = compute_cost(X, y, theta)\n",
        "\n",
        "      if(cost == float('inf')):\n",
        "        print('ERROR: The learning rate, alpha, is too large.')\n",
        "        print()\n",
        "        break;\n",
        "\n",
        "      # Check for convergence.\n",
        "      # If the previous cost is the same as the current cost then\n",
        "      # we have converged to the minimum.\n",
        "      if (iterations > 0 and cost_history[iterations - 1] == cost):\n",
        "        converged = True\n",
        "      else:\n",
        "        # Increase the number of iterations\n",
        "        iterations = iterations + 1\n",
        "        # Track our cost history. We will graph this to see how cost\n",
        "        # decreases with the number of iterations.\n",
        "        cost_history.append(cost)\n",
        "        theta_history.append(theta)\n",
        "      \n",
        "    return theta_history, cost_history, iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOPHc7RItlce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run gradent descent and calculate the optimal theta values with the\n",
        "# minimal cost which will draw a line that directly interstects our data.\n",
        "thetas, costs, iterations = gradient_descent(X, y, theta, alpha = .024)\n",
        "\n",
        "optimal_theta0 = thetas[iterations - 1][0, 0]\n",
        "optimal_theta1 = thetas[iterations - 1][0, 1]\n",
        "\n",
        "print(f'Optimal theta values: {optimal_theta0} and {optimal_theta1}')\n",
        "print(f'Cost................: {costs[iterations - 1]}')\n",
        "print(f'Iterations..........: {iterations:,}')\n",
        "print('')\n",
        "%time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMvr3zoeX3Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.plot(\n",
        "    [i[0][0,0] for i in thetas],\n",
        "    [i[0][0,1] for i in thetas],\n",
        "    costs)\n",
        "\n",
        "ax.set_xlabel('Theta0')\n",
        "ax.set_ylabel('Theta1')\n",
        "ax.set_zlabel('Cost')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzHB51pXf9uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Return evenly spaced numbers over a specified interval of 100.\n",
        "x = np.linspace(df_raw.Population.min(), df_raw.Population.max(), 100)\n",
        "f = optimal_theta0 + (optimal_theta1 * x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,8))\n",
        "\n",
        "ax.plot(x, f, 'r', label='Prediction')\n",
        "ax.scatter(df_raw.Population, df_raw.Profit, label='Training Data')\n",
        "ax.legend(loc = 2)\n",
        "ax.set_xlabel('Population')\n",
        "ax.set_ylabel('Profit')\n",
        "ax.set_title('Predicted Profit vs. Population Size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Xyc9z8reJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(np.arange(iterations), costs, 'r')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_ylabel('Cost')\n",
        "ax.set_title('Error vs. Training Epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}