{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Distance Between Clusters\n",
    "\n",
    "Distance between clusters is computed by identifying which features to measure distance between (Linkage Metric) and measuring the actual distance between the identified features using the Minkowski method.\n",
    "\n",
    "- **Single-Linkage** considers the distance between clusters using the shortest distance from any member (example) of one cluster to any member of the other cluster.\n",
    "\n",
    "    ![](https://github.com/harperd/machine-learning/blob/master/images/single-linkage.jpg?raw=1)\n",
    "\n",
    "- **Complete-Linkage** considers the distance between clusters using the greatest distance from any member (example) of one cluster to any member of the other cluster.\n",
    "\n",
    "     ![](https://github.com/harperd/machine-learning/blob/master/images/complete-linkage.jpg?raw=1)\n",
    "\n",
    "- **Average-Linkage** considers the distance between clusters using the average distance from any member (example) of one cluster to any member of the other cluster.\n",
    "\n",
    "    ![](https://github.com/harperd/machine-learning/blob/master/images/average-linkage.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minkowski Metric\n",
    "\n",
    "This is the basis for finding distances between Features (or Examples) for *Euclidean*, which is the most common, and *Manhattan* distances:\n",
    "\n",
    "   ![](https://github.com/harperd/machine-learning/blob/master/images/minkowski.jpg?raw=1)\n",
    "\n",
    "Two different ways to use the equation. For *Euclidean Distance* (straight line between two points) use p = 2, For *Manhattan Distance* (along axises only) use p = 1.\n",
    "\n",
    "  ![](https://github.com/harperd/machine-learning/blob/master/images/manhattan-euclidean.jpg?raw=1)\n",
    "\n",
    "> **NOTE** Euclidean is mostly used. Manhattan is sometimes used when different Features (or Dimensions) are not comparable or higher dimensional data. For example, age vs. other Features that are binary in nature, such as “wears glasses”.\n",
    "\n",
    "**Other distance metrics:** Chebyshev, Cosine, Canberra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance measurements with 2-dimensional vectors\n",
      "\n",
      "Euclidean distance is 3.9109690600209945\n",
      "Manhattan distance is 5.412665104904623\n",
      "Chebyshev distance is 3.2751942313846394\n",
      "Canberra distance is 1.531430912244757\n",
      "Cosine distance is 0.614950275085963\n"
     ]
    }
   ],
   "source": [
    "# For computing distance between vectors and clusters\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "# For creating random clusters\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# For K-Means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, _ = make_blobs(n_samples=10, centers=3, n_features=2, random_state=0)\n",
    "\n",
    "predictor = KMeans(\n",
    "        # The number of clusters to form as well as the number of centroids to generate.\n",
    "        n_clusters = 2, \n",
    "        # Method for initialization, defaults to ‘k-means++’:\n",
    "        # ‘k-means++’: selects initial cluster centers for k-mean clustering in a smart way to \n",
    "        #              speed up convergence.\n",
    "        # ‘random’: choose k observations (rows) at random from data for the initial centroids.\n",
    "        init = 'k-means++',\n",
    "        # Maximum number of iterations of the k-means algorithm for a single run.\n",
    "        max_iter = 300,\n",
    "        # Number of time the k-means algorithm will be run with different centroid seeds. \n",
    "        # The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "        n_init = 10,\n",
    "        # Determines random number generation for centroid initialization. Use an int to \n",
    "        # make the randomness deterministic. \n",
    "        random_state = 0)\n",
    "predictor.fit(X)\n",
    "\n",
    "# Create some clusters with random data\n",
    "cluster_A = predictor.cluster_centers_[0]\n",
    "cluster_B = predictor.cluster_centers_[1]\n",
    "dimensions = len(cluster_A)\n",
    "\n",
    "print(f'Distance measurements with {dimensions}-dimensional vectors')\n",
    "print()\n",
    "print('Euclidean distance is', dist.euclidean(cluster_A, cluster_B))\n",
    "print('Manhattan distance is', dist.cityblock(cluster_A, cluster_B))\n",
    "print('Chebyshev distance is', dist.chebyshev(cluster_A, cluster_B))\n",
    "print('Canberra distance is', dist.canberra(cluster_A, cluster_B))\n",
    "print('Cosine distance is', dist.cosine(cluster_A, cluster_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
